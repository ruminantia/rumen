[DEFAULT]
# Default LLM provider settings
provider = gemini
model = gemini-2.5-flash-lite
base_url = https://generativelanguage.googleapis.com/v1beta
temperature = 0.7
max_tokens = 2048
top_p = 0.9
thinking_enabled = false
search_enabled = false
retry_attempts = 3
retry_delay = 2

# API settings
api_host = 0.0.0.0
api_port = 8000
api_workers = 1

# File monitoring settings
monitor_interval = 5
file_timeout = 30

# Output settings
output_format = markdown
output_directory = /app/bolus

[gemini]
# Gemini specific settings
# No additional headers needed for Gemini

[openai]
# OpenAI specific settings
base_url = https://api.openai.com/v1

[openrouter]
# OpenRouter specific settings
base_url = https://openrouter.ai/api/v1
http_referer =
x_title =

[deepseek]
# DeepSeek specific settings
base_url = https://api.deepseek.com/v1

# Folder-specific configurations
# Each section defines a folder to monitor and its specific prompt
[worldnews]
folder_path = /app/input/worldnews
enabled = false
system_prompt = You are a news analyst. Analyze the provided news article and extract key information, summarize the main points, and provide context.
user_prompt_template = Please analyze this news article: {content}
provider = gemini
model = gemini-2.5-flash-lite
temperature = 0.3
max_tokens = 1024
output_format = markdown

[research]
folder_path = /app/input/research
enabled = false
system_prompt = You are a research assistant. Analyze the provided research material and extract key insights, summarize findings, and identify potential applications.
user_prompt_template = Please analyze this research material: {content}
provider = gemini
model = gemini-2.5-flash-lite
temperature = 0.5
max_tokens = 2048
output_format = markdown

[summarization]
folder_path = /app/input/summarization
enabled = false
system_prompt = You are a summarization expert. Create a concise summary of the provided content while preserving key information.
user_prompt_template = Please summarize this content: {content}
# provider = gemini
# model = gemini-2.5-flash-lite
temperature = 0.2
max_tokens = 512
output_format = markdown

# Add more folder configurations as needed
# [custom_folder_name]
# folder_path = /app/input/custom_folder_name
# enabled = false
# system_prompt = Your custom system prompt
# user_prompt_template = Your custom user prompt template with {content} placeholder
# provider = gemini
# model = gemini-2.5-flash-lite
# temperature = 0.7
# max_tokens = 2048
# output_format = markdown
